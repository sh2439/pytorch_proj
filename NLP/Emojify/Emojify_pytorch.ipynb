{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Emojify"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project implements \"Emojify\" with Pytorch.\n",
    "\n",
    "- Input: Sentences \n",
    "- Output: Emoji (cast as numerical labels)ü§î\n",
    "\n",
    "For example:\n",
    "Food is life üç¥\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Acknowledgement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some ideas and the structure of the neural network come from [Coursera Deep Learning Specialization](https://www.coursera.org/specializations/deep-learning).\n",
    "\n",
    "The dataset can be download from [here](https://drive.google.com/drive/folders/1vXgzjhALvH981cNYZwlQ1wZJ_NE_Xd44?usp=sharing)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import os.path as osp\n",
    "\n",
    "# import pytorch packages\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "from torch.utils import data\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "import emoji"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Prepare the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preview the dataset. The original datasets are in csv format. The first column '0' shows all the training data and the second column '1' shows all the labels. The ground truth labels can cast to the emojis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>never talk to me again</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I am proud of your achievements</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>It is the worst day in my life</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Miss you so much</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>food is life</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 0  1   2     3\n",
       "0           never talk to me again  3 NaN   NaN\n",
       "1  I am proud of your achievements  2 NaN   NaN\n",
       "2   It is the worst day in my life  3 NaN   NaN\n",
       "3                 Miss you so much  0 NaN   [0]\n",
       "4                     food is life  4 NaN   NaN"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_root = 'data'\n",
    "train_name = 'train_emoji.csv'\n",
    "test_name = 'tess.csv'\n",
    "\n",
    "# preview the dataset\n",
    "dataset_preview = pd.read_csv(osp.join(data_root, train_name), header = None)\n",
    "dataset_preview.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cast the labels to real emojis.ü§î "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check the labels and their corresponding emojis:\n",
      "\n",
      "Label:0, and its corresponding emoji:‚ù§Ô∏è\n",
      "Label:1, and its corresponding emoji:‚öæ\n",
      "Label:2, and its corresponding emoji:üòÑ\n",
      "Label:3, and its corresponding emoji:üòû\n",
      "Label:4, and its corresponding emoji:üç¥\n",
      "\n",
      "Preview dataset:\n",
      "never talk to me again üòû\n",
      "I am proud of your achievements üòÑ\n",
      "It is the worst day in my life üòû\n",
      "Miss you so much ‚ù§Ô∏è\n",
      "food is life üç¥\n"
     ]
    }
   ],
   "source": [
    "def to_emoji(emoji_dict, label):\n",
    "    \"\"\" Cast a numerical label to the emoji\n",
    "    \"\"\"\n",
    "    \n",
    "    emoji_new = emoji.emojize(emoji_dict[label],use_aliases=True)\n",
    "    \n",
    "    return emoji_new\n",
    "\n",
    "emoji_dictionary = {0: \"\\u2764\\uFE0F\",    # :heart: prints a black instead of red heart depending on the font\n",
    "                    1: \":baseball:\",\n",
    "                    2: \":smile:\",\n",
    "                    3: \":disappointed:\",\n",
    "                    4: \":fork_and_knife:\"}\n",
    "\n",
    "\n",
    "print('Check the labels and their corresponding emojis:\\n')\n",
    "for label in emoji_dictionary.keys():\n",
    "\n",
    "    print('Label:{}, and its corresponding emoji:{}'.format(label, to_emoji(emoji_dictionary, label)))\n",
    "    \n",
    "print('\\nPreview dataset:')\n",
    "for i in range(5):\n",
    "    print(dataset_preview[0][i], to_emoji(emoji_dictionary, dataset_preview[1][i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build the dataset class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class emoji_dataset(data.Dataset):\n",
    "    \n",
    "    def __init__(self, data_root, data_name):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        \n",
    "        self.dataset = pd.read_csv(osp.join(data_root, data_name), header = None)\n",
    "        self.length = len(self.dataset)\n",
    "        self.data = self.dataset[0]\n",
    "        self.labels = self.dataset[1]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "    \n",
    "    def data(self,index):\n",
    "        \"\"\"return the data.\n",
    "        \"\"\"\n",
    "        return self.data[index]\n",
    "    \n",
    "    def label(self,index):\n",
    "        \"\"\"return the labels of dataset.\n",
    "        \"\"\"\n",
    "        return self.labels[index]\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        X = self.data[index]\n",
    "        y = self.labels[index]\n",
    "        \n",
    "        return X, y\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "she did not answer my text  üòû\n",
      "Length of training examples:132 \n",
      "length of test examples:56\n"
     ]
    }
   ],
   "source": [
    "train_dataset = emoji_dataset(data_root, train_name)\n",
    "test_dataset = emoji_dataset(data_root, test_name)\n",
    "\n",
    "print(train_dataset[10][0], to_emoji(emoji_dictionary, train_dataset[10][1]))\n",
    "\n",
    "print('Length of training examples:{} \\nlength of test examples:{}'.format(len(train_dataset), len(test_dataset)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset = train_dataset,\n",
    "                                          shuffle = True,\n",
    "                                           batch_size = batch_size,\n",
    "                                          )\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset = test_dataset,\n",
    "                                          shuffle = False,\n",
    "                                           batch_size = 8,\n",
    "                                          )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Preprocess the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Several helper functions are needed to preprocess the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Read the GloVe\n",
    "Read the global vectors for word representation file. Get the word embeddings and word index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "name = '/home/sh2439/pytorch_tutorials/Sequence Model/Week 2/Word Vector Representation/glove.6B.50d.txt'\n",
    "\n",
    "# Read the GloVe text file and return the words.\n",
    "def read_glove(name):\n",
    "    \"\"\"Given the path/name of the glove file, return the words(set) and word2vec_map(a python dict)\n",
    "    \"\"\"\n",
    "    file = open(name, 'r')\n",
    "    # Create set for words and a dictionary for words and their corresponding  \n",
    "    words = set()\n",
    "    word2vec_map = {}\n",
    "    \n",
    "    data = file.readlines()\n",
    "    for line in data:\n",
    "        # add word to the words set.\n",
    "        word = line.split()[0]\n",
    "        words.add(word)\n",
    "        \n",
    "        word2vec_map[word] = np.array(line.split()[1:], dtype = np.float64)\n",
    "        \n",
    "    i = 1\n",
    "    word2index = {}\n",
    "    index2word = {}\n",
    "    for word in words:\n",
    "        word2index[word] = i\n",
    "        index2word[i] = word\n",
    "        i = i+1\n",
    "        \n",
    "    return words, word2vec_map, word2index, index2word\n",
    "\n",
    "words, word2vec_map, word2index, index2word = read_glove(name)\n",
    "# Read the GloVe text file and return the words.\n",
    "def read_glove(name):\n",
    "    \"\"\"Given the path/name of the glove file, return the words(set), word2vec_map(a python dict),\n",
    "        word2index(a python dict), index2word(a python dict).\n",
    "    \"\"\"\n",
    "    file = open(name, 'r')\n",
    "    # Create set for words and a dictionary for words and their corresponding  \n",
    "    words = set()\n",
    "    word2vec_map = {}\n",
    "    \n",
    "    data = file.readlines()\n",
    "    for line in data:\n",
    "        # add word to the words set.\n",
    "        word = line.split()[0]\n",
    "        words.add(word)\n",
    "        \n",
    "        word2vec_map[word] = np.array(line.split()[1:], dtype = np.float64)\n",
    "        \n",
    "    i = 1\n",
    "    word2index = {}\n",
    "    index2word = {}\n",
    "    for word in words:\n",
    "        word2index[word] = i\n",
    "        index2word[i] = word\n",
    "        i = i+1\n",
    "        \n",
    "    return words, word2vec_map, word2index, index2word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "words, word2vec_map, word2index, index2word = read_glove(name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index of word hello = 60101\n",
      "Word of index 121098 = h2co3\n",
      "Embedding vector of word hello = [-0.38497   0.80092   0.064106 -0.28355  -0.026759 -0.34532  -0.64253\n",
      " -0.11729  -0.33257   0.55243  -0.087813  0.9035    0.47102   0.56657\n",
      "  0.6985   -0.35229  -0.86542   0.90573   0.03576  -0.071705 -0.12327\n",
      "  0.54923   0.47005   0.35572   1.2611   -0.67581  -0.94983   0.68666\n",
      "  0.3871   -1.3492    0.63512   0.46416  -0.48814   0.83827  -0.9246\n",
      " -0.33722   0.53741  -1.0616   -0.081403 -0.67111   0.30923  -0.3923\n",
      " -0.55002  -0.68827   0.58049  -0.11626   0.013139 -0.57654   0.048833\n",
      "  0.67204 ]\n"
     ]
    }
   ],
   "source": [
    "word = 'hello'\n",
    "index = 121098\n",
    "print('Index of word',word, '=', word2index[word])\n",
    "print('Word of index',index, '=', index2word[index])\n",
    "print('Embedding vector of word', word, '=', word2vec_map[word])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Convert the sentences input to indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a helper function to convert sentence input numerical inputs.  \n",
    "If the length of the sentence is less than the maximum length, padd the sentence with 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_index(sentences, word2index, max_length):\n",
    "    \"\"\" Given the word2index dict, maximum length, and inputs, return the numerical inputs\n",
    "    \"\"\"\n",
    "    num = len(sentences)\n",
    "    out = torch.zeros(num, max_length).long()\n",
    "    \n",
    "    for idx, sen in enumerate(sentences):\n",
    "        \n",
    "        sen = sen.lower().split()\n",
    "        \n",
    "        j = 0\n",
    "        \n",
    "        for word in sen:\n",
    "            word_idx = word2index[word]\n",
    "            out[idx, j] = word_idx\n",
    "            j += 1\n",
    "            \n",
    "            if j >= max_length:\n",
    "                break\n",
    "            \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The input tensor of 1st sentence:  tensor([228682, 340541,  34521,  58080,  11905])\n",
      "The input tensor of 4th sentence:  tensor([143666, 194081, 268164, 196552,      0])\n"
     ]
    }
   ],
   "source": [
    "out = to_index(train_dataset.data, word2index, max_length = 5)\n",
    "print('The input tensor of 1st sentence: ', out[0])\n",
    "print('The input tensor of 4th sentence: ', out[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Create embedding weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the weights: torch.Size([400001, 50])\n"
     ]
    }
   ],
   "source": [
    "emb_weights = torch.zeros(len(word2vec_map)+1, 50)\n",
    "for word, idx in word2index.items():\n",
    "#     print(word)\n",
    "    emb_weights[idx,:] = torch.tensor(word2vec_map[word])\n",
    "\n",
    "print('Size of the weights:', emb_weights.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Build the model class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Emoji_Net(nn.Module):\n",
    "    \"\"\" The emoji net uses embedding layer, lstm layer and fully-connected layer.\n",
    "    \"\"\"\n",
    "    def __init__(self,layer_num,input_dim, hidden_dim, output_dim, weights):\n",
    "        super(Emoji_Net, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.layer_num = layer_num\n",
    "        self.output_dim = output_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "        # the embedding layer\n",
    "        weights = weights.to(device)\n",
    "        self.embedding = nn.Embedding.from_pretrained(weights)\n",
    "        \n",
    "        # the lstm layer\n",
    "        self.lstm = nn.LSTM(input_size = self.input_dim, hidden_size = self.hidden_dim, \n",
    "                            num_layers = self.layer_num, batch_first = True, dropout = 0.8,bidirectional = True)\n",
    "        self.dropout = nn.Dropout(0.6)\n",
    "        \n",
    "        # the output layer\n",
    "        self.fc = nn.Linear(hidden_dim*2, output_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        \n",
    "        # h0\n",
    "        h0 = Variable(torch.zeros(2*self.layer_num, x.size(0), self.hidden_dim)).to(device)\n",
    "        \n",
    "        # c0\n",
    "        c0 = Variable(torch.zeros(2*self.layer_num, x.size(0), self.hidden_dim)).to(device)\n",
    "        \n",
    "        # embedding\n",
    "        x = self.embedding(x)\n",
    "        # lstm\n",
    "        x, (hn ,cn) = self.lstm(x, (h0, c0))\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        # output layer\n",
    "        x = self.fc(x[:, -1, :])\n",
    "        \n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instantiate the model class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Emoji_Net(\n",
       "  (embedding): Embedding(400001, 50)\n",
       "  (lstm): LSTM(50, 128, num_layers=2, batch_first=True, dropout=0.8, bidirectional=True)\n",
       "  (dropout): Dropout(p=0.6)\n",
       "  (fc): Linear(in_features=256, out_features=5, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available else 'cpu')\n",
    "\n",
    "\n",
    "layer_num = 2\n",
    "input_dim = 50\n",
    "hidden_dim = 128\n",
    "output_dim = 5\n",
    "\n",
    "\n",
    "emoji_net = Emoji_Net(layer_num, input_dim,hidden_dim, output_dim, emb_weights)\n",
    "\n",
    "emoji_net.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Loss and Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "learning_rate = 0.001\n",
    "optimizer = torch.optim.Adam(emoji_net.parameters(), lr = learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define save model function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_best(is_best, best_accuracy, model, epoch, path):\n",
    "    filename = path + 'best_model.pth'\n",
    "    \n",
    "    if is_best:\n",
    "        if not osp.exists(path):\n",
    "            os.makedirs(path)\n",
    "        torch.save({'epoch':epoch,\n",
    "                   'model_state_dict':model.state_dict(),\n",
    "                    'best_accuracy':best_accuracy\n",
    "                   }, filename)\n",
    "        \n",
    "        print(best_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start training..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6cb3e1c2a4214d4c9512e6519131c4f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=200), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, iters: 0.0, loss: 1.5978573560714722\n",
      "Epoch: 0, Test Accuracy:26.785714285714285\n",
      "26.785714285714285\n",
      "epoch: 1, iters: 5.0, loss: 1.593022346496582\n",
      "Epoch: 1, Test Accuracy:26.785714285714285\n",
      "epoch: 2, iters: 10.0, loss: 1.5806373357772827\n",
      "Epoch: 2, Test Accuracy:26.785714285714285\n",
      "epoch: 3, iters: 15.0, loss: 1.5557117462158203\n",
      "Epoch: 3, Test Accuracy:26.785714285714285\n",
      "epoch: 4, iters: 20.0, loss: 1.6087793111801147\n",
      "Epoch: 4, Test Accuracy:26.785714285714285\n",
      "epoch: 5, iters: 25.0, loss: 1.5102040767669678\n",
      "Epoch: 5, Test Accuracy:26.785714285714285\n",
      "epoch: 6, iters: 30.0, loss: 1.4841002225875854\n",
      "Epoch: 6, Test Accuracy:26.785714285714285\n",
      "epoch: 7, iters: 35.0, loss: 1.619018793106079\n",
      "Epoch: 7, Test Accuracy:33.92857142857143\n",
      "33.92857142857143\n",
      "epoch: 8, iters: 40.0, loss: 1.5192112922668457\n",
      "Epoch: 8, Test Accuracy:33.92857142857143\n",
      "epoch: 9, iters: 45.0, loss: 1.5225038528442383\n",
      "Epoch: 9, Test Accuracy:33.92857142857143\n",
      "epoch: 10, iters: 50.0, loss: 1.5658466815948486\n",
      "Epoch: 10, Test Accuracy:28.571428571428573\n",
      "epoch: 11, iters: 55.0, loss: 1.421264410018921\n",
      "Epoch: 11, Test Accuracy:25.0\n",
      "epoch: 12, iters: 60.0, loss: 1.3923743963241577\n",
      "Epoch: 12, Test Accuracy:30.357142857142858\n",
      "epoch: 13, iters: 65.0, loss: 1.2607353925704956\n",
      "Epoch: 13, Test Accuracy:35.714285714285715\n",
      "35.714285714285715\n",
      "epoch: 14, iters: 70.0, loss: 1.4001190662384033\n",
      "Epoch: 14, Test Accuracy:33.92857142857143\n",
      "epoch: 15, iters: 75.0, loss: 1.2285114526748657\n",
      "Epoch: 15, Test Accuracy:32.142857142857146\n",
      "epoch: 16, iters: 80.0, loss: 1.2608091831207275\n",
      "Epoch: 16, Test Accuracy:32.142857142857146\n",
      "epoch: 17, iters: 85.0, loss: 1.4252922534942627\n",
      "Epoch: 17, Test Accuracy:35.714285714285715\n",
      "epoch: 18, iters: 90.0, loss: 1.2610769271850586\n",
      "Epoch: 18, Test Accuracy:35.714285714285715\n",
      "epoch: 19, iters: 95.0, loss: 1.2369978427886963\n",
      "Epoch: 19, Test Accuracy:39.285714285714285\n",
      "39.285714285714285\n",
      "epoch: 20, iters: 100.0, loss: 1.0769362449645996\n",
      "Epoch: 20, Test Accuracy:35.714285714285715\n",
      "epoch: 21, iters: 105.0, loss: 1.0554349422454834\n",
      "Epoch: 21, Test Accuracy:30.357142857142858\n",
      "epoch: 22, iters: 110.0, loss: 1.058711051940918\n",
      "Epoch: 22, Test Accuracy:33.92857142857143\n",
      "epoch: 23, iters: 115.0, loss: 1.0198317766189575\n",
      "Epoch: 23, Test Accuracy:30.357142857142858\n",
      "epoch: 24, iters: 120.0, loss: 0.9886799454689026\n",
      "Epoch: 24, Test Accuracy:33.92857142857143\n",
      "epoch: 25, iters: 125.0, loss: 1.0453203916549683\n",
      "Epoch: 25, Test Accuracy:42.857142857142854\n",
      "42.857142857142854\n",
      "epoch: 26, iters: 130.0, loss: 1.0370268821716309\n",
      "Epoch: 26, Test Accuracy:46.42857142857143\n",
      "46.42857142857143\n",
      "epoch: 27, iters: 135.0, loss: 0.9255284070968628\n",
      "Epoch: 27, Test Accuracy:44.642857142857146\n",
      "epoch: 28, iters: 140.0, loss: 0.9075564742088318\n",
      "Epoch: 28, Test Accuracy:50.0\n",
      "50.0\n",
      "epoch: 29, iters: 145.0, loss: 0.9165506362915039\n",
      "Epoch: 29, Test Accuracy:53.57142857142857\n",
      "53.57142857142857\n",
      "epoch: 30, iters: 150.0, loss: 0.7080895304679871\n",
      "Epoch: 30, Test Accuracy:55.357142857142854\n",
      "55.357142857142854\n",
      "epoch: 31, iters: 155.0, loss: 0.662257730960846\n",
      "Epoch: 31, Test Accuracy:51.785714285714285\n",
      "epoch: 32, iters: 160.0, loss: 0.7707993984222412\n",
      "Epoch: 32, Test Accuracy:51.785714285714285\n",
      "epoch: 33, iters: 165.0, loss: 0.5719679594039917\n",
      "Epoch: 33, Test Accuracy:58.92857142857143\n",
      "58.92857142857143\n",
      "epoch: 34, iters: 170.0, loss: 0.6675254106521606\n",
      "Epoch: 34, Test Accuracy:60.714285714285715\n",
      "60.714285714285715\n",
      "epoch: 35, iters: 175.0, loss: 0.7422441840171814\n",
      "Epoch: 35, Test Accuracy:53.57142857142857\n",
      "epoch: 36, iters: 180.0, loss: 0.8301177620887756\n",
      "Epoch: 36, Test Accuracy:60.714285714285715\n",
      "epoch: 37, iters: 185.0, loss: 0.6355689764022827\n",
      "Epoch: 37, Test Accuracy:55.357142857142854\n",
      "epoch: 38, iters: 190.0, loss: 0.8119186162948608\n",
      "Epoch: 38, Test Accuracy:58.92857142857143\n",
      "epoch: 39, iters: 195.0, loss: 0.9784860014915466\n",
      "Epoch: 39, Test Accuracy:50.0\n",
      "epoch: 40, iters: 200.0, loss: 0.6089549660682678\n",
      "Epoch: 40, Test Accuracy:53.57142857142857\n",
      "epoch: 41, iters: 205.0, loss: 0.6162455081939697\n",
      "Epoch: 41, Test Accuracy:58.92857142857143\n",
      "epoch: 42, iters: 210.0, loss: 0.7148448824882507\n",
      "Epoch: 42, Test Accuracy:66.07142857142857\n",
      "66.07142857142857\n",
      "epoch: 43, iters: 215.0, loss: 0.5015584230422974\n",
      "Epoch: 43, Test Accuracy:60.714285714285715\n",
      "epoch: 44, iters: 220.0, loss: 0.5550225973129272\n",
      "Epoch: 44, Test Accuracy:58.92857142857143\n",
      "epoch: 45, iters: 225.0, loss: 0.5766338109970093\n",
      "Epoch: 45, Test Accuracy:64.28571428571429\n",
      "epoch: 46, iters: 230.0, loss: 0.5634678602218628\n",
      "Epoch: 46, Test Accuracy:58.92857142857143\n",
      "epoch: 47, iters: 235.0, loss: 0.5470969080924988\n",
      "Epoch: 47, Test Accuracy:53.57142857142857\n",
      "epoch: 48, iters: 240.0, loss: 0.6186813712120056\n",
      "Epoch: 48, Test Accuracy:55.357142857142854\n",
      "epoch: 49, iters: 245.0, loss: 0.5189855694770813\n",
      "Epoch: 49, Test Accuracy:57.142857142857146\n",
      "epoch: 50, iters: 250.0, loss: 0.5452263355255127\n",
      "Epoch: 50, Test Accuracy:60.714285714285715\n",
      "epoch: 51, iters: 255.0, loss: 0.5259675979614258\n",
      "Epoch: 51, Test Accuracy:64.28571428571429\n",
      "epoch: 52, iters: 260.0, loss: 0.6036195158958435\n",
      "Epoch: 52, Test Accuracy:62.5\n",
      "epoch: 53, iters: 265.0, loss: 0.4592323899269104\n",
      "Epoch: 53, Test Accuracy:66.07142857142857\n",
      "epoch: 54, iters: 270.0, loss: 0.5011690855026245\n",
      "Epoch: 54, Test Accuracy:66.07142857142857\n",
      "epoch: 55, iters: 275.0, loss: 0.6015995740890503\n",
      "Epoch: 55, Test Accuracy:67.85714285714286\n",
      "67.85714285714286\n",
      "epoch: 56, iters: 280.0, loss: 0.4543684720993042\n",
      "Epoch: 56, Test Accuracy:69.64285714285714\n",
      "69.64285714285714\n",
      "epoch: 57, iters: 285.0, loss: 0.41245779395103455\n",
      "Epoch: 57, Test Accuracy:58.92857142857143\n",
      "epoch: 58, iters: 290.0, loss: 0.5010132789611816\n",
      "Epoch: 58, Test Accuracy:57.142857142857146\n",
      "epoch: 59, iters: 295.0, loss: 0.4305422008037567\n",
      "Epoch: 59, Test Accuracy:67.85714285714286\n",
      "epoch: 60, iters: 300.0, loss: 0.41845840215682983\n",
      "Epoch: 60, Test Accuracy:58.92857142857143\n",
      "epoch: 61, iters: 305.0, loss: 0.5954930186271667\n",
      "Epoch: 61, Test Accuracy:67.85714285714286\n",
      "epoch: 62, iters: 310.0, loss: 0.4270206093788147\n",
      "Epoch: 62, Test Accuracy:67.85714285714286\n",
      "epoch: 63, iters: 315.0, loss: 0.462128221988678\n",
      "Epoch: 63, Test Accuracy:66.07142857142857\n",
      "epoch: 64, iters: 320.0, loss: 0.4617515504360199\n",
      "Epoch: 64, Test Accuracy:66.07142857142857\n",
      "epoch: 65, iters: 325.0, loss: 0.5612410306930542\n",
      "Epoch: 65, Test Accuracy:64.28571428571429\n",
      "epoch: 66, iters: 330.0, loss: 0.7272714972496033\n",
      "Epoch: 66, Test Accuracy:60.714285714285715\n",
      "epoch: 67, iters: 335.0, loss: 0.72981196641922\n",
      "Epoch: 67, Test Accuracy:66.07142857142857\n",
      "epoch: 68, iters: 340.0, loss: 0.611905038356781\n",
      "Epoch: 68, Test Accuracy:58.92857142857143\n",
      "epoch: 69, iters: 345.0, loss: 0.6955139636993408\n",
      "Epoch: 69, Test Accuracy:69.64285714285714\n",
      "epoch: 70, iters: 350.0, loss: 0.5844182372093201\n",
      "Epoch: 70, Test Accuracy:60.714285714285715\n",
      "epoch: 71, iters: 355.0, loss: 0.40852442383766174\n",
      "Epoch: 71, Test Accuracy:60.714285714285715\n",
      "epoch: 72, iters: 360.0, loss: 0.4148252606391907\n",
      "Epoch: 72, Test Accuracy:66.07142857142857\n",
      "epoch: 73, iters: 365.0, loss: 0.5463668704032898\n",
      "Epoch: 73, Test Accuracy:71.42857142857143\n",
      "71.42857142857143\n",
      "epoch: 74, iters: 370.0, loss: 0.42360472679138184\n",
      "Epoch: 74, Test Accuracy:69.64285714285714\n",
      "epoch: 75, iters: 375.0, loss: 0.5416308045387268\n",
      "Epoch: 75, Test Accuracy:64.28571428571429\n",
      "epoch: 76, iters: 380.0, loss: 0.40471670031547546\n",
      "Epoch: 76, Test Accuracy:67.85714285714286\n",
      "epoch: 77, iters: 385.0, loss: 0.4263327419757843\n",
      "Epoch: 77, Test Accuracy:69.64285714285714\n",
      "epoch: 78, iters: 390.0, loss: 0.3733314573764801\n",
      "Epoch: 78, Test Accuracy:67.85714285714286\n",
      "epoch: 79, iters: 395.0, loss: 0.425430029630661\n",
      "Epoch: 79, Test Accuracy:62.5\n",
      "epoch: 80, iters: 400.0, loss: 0.595462441444397\n",
      "Epoch: 80, Test Accuracy:67.85714285714286\n",
      "epoch: 81, iters: 405.0, loss: 0.5547740459442139\n",
      "Epoch: 81, Test Accuracy:62.5\n",
      "epoch: 82, iters: 410.0, loss: 0.43243974447250366\n",
      "Epoch: 82, Test Accuracy:57.142857142857146\n",
      "epoch: 83, iters: 415.0, loss: 0.4653150737285614\n",
      "Epoch: 83, Test Accuracy:60.714285714285715\n",
      "epoch: 84, iters: 420.0, loss: 0.5186057090759277\n",
      "Epoch: 84, Test Accuracy:62.5\n",
      "epoch: 85, iters: 425.0, loss: 0.43923094868659973\n",
      "Epoch: 85, Test Accuracy:75.0\n",
      "75.0\n",
      "epoch: 86, iters: 430.0, loss: 0.43205422163009644\n",
      "Epoch: 86, Test Accuracy:69.64285714285714\n",
      "epoch: 87, iters: 435.0, loss: 0.32949769496917725\n",
      "Epoch: 87, Test Accuracy:71.42857142857143\n",
      "epoch: 88, iters: 440.0, loss: 0.37080663442611694\n",
      "Epoch: 88, Test Accuracy:62.5\n",
      "epoch: 89, iters: 445.0, loss: 0.4308290183544159\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 89, Test Accuracy:60.714285714285715\n",
      "epoch: 90, iters: 450.0, loss: 0.39030885696411133\n",
      "Epoch: 90, Test Accuracy:60.714285714285715\n",
      "epoch: 91, iters: 455.0, loss: 0.5294881463050842\n",
      "Epoch: 91, Test Accuracy:66.07142857142857\n",
      "epoch: 92, iters: 460.0, loss: 0.5831853747367859\n",
      "Epoch: 92, Test Accuracy:64.28571428571429\n",
      "epoch: 93, iters: 465.0, loss: 0.5130822658538818\n",
      "Epoch: 93, Test Accuracy:62.5\n",
      "epoch: 94, iters: 470.0, loss: 0.21867796778678894\n",
      "Epoch: 94, Test Accuracy:58.92857142857143\n",
      "epoch: 95, iters: 475.0, loss: 0.30327343940734863\n",
      "Epoch: 95, Test Accuracy:57.142857142857146\n",
      "epoch: 96, iters: 480.0, loss: 0.30814459919929504\n",
      "Epoch: 96, Test Accuracy:60.714285714285715\n",
      "epoch: 97, iters: 485.0, loss: 0.42968326807022095\n",
      "Epoch: 97, Test Accuracy:62.5\n",
      "epoch: 98, iters: 490.0, loss: 0.3651081323623657\n",
      "Epoch: 98, Test Accuracy:64.28571428571429\n",
      "epoch: 99, iters: 495.0, loss: 0.3736293315887451\n",
      "Epoch: 99, Test Accuracy:64.28571428571429\n",
      "epoch: 100, iters: 500.0, loss: 0.4266050457954407\n",
      "Epoch: 100, Test Accuracy:64.28571428571429\n",
      "epoch: 101, iters: 505.0, loss: 0.3273064196109772\n",
      "Epoch: 101, Test Accuracy:64.28571428571429\n",
      "epoch: 102, iters: 510.0, loss: 0.35005125403404236\n",
      "Epoch: 102, Test Accuracy:67.85714285714286\n",
      "epoch: 103, iters: 515.0, loss: 0.4803495407104492\n",
      "Epoch: 103, Test Accuracy:67.85714285714286\n",
      "epoch: 104, iters: 520.0, loss: 0.5659538507461548\n",
      "Epoch: 104, Test Accuracy:64.28571428571429\n",
      "epoch: 105, iters: 525.0, loss: 0.35165178775787354\n",
      "Epoch: 105, Test Accuracy:75.0\n",
      "epoch: 106, iters: 530.0, loss: 0.4246121644973755\n",
      "Epoch: 106, Test Accuracy:69.64285714285714\n",
      "epoch: 107, iters: 535.0, loss: 0.3359236717224121\n",
      "Epoch: 107, Test Accuracy:67.85714285714286\n",
      "epoch: 108, iters: 540.0, loss: 0.41360414028167725\n",
      "Epoch: 108, Test Accuracy:66.07142857142857\n",
      "epoch: 109, iters: 545.0, loss: 0.33694538474082947\n",
      "Epoch: 109, Test Accuracy:66.07142857142857\n",
      "epoch: 110, iters: 550.0, loss: 0.3471348285675049\n",
      "Epoch: 110, Test Accuracy:50.0\n",
      "epoch: 111, iters: 555.0, loss: 1.8702665567398071\n",
      "Epoch: 111, Test Accuracy:62.5\n",
      "epoch: 112, iters: 560.0, loss: 1.0938422679901123\n",
      "Epoch: 112, Test Accuracy:62.5\n",
      "epoch: 113, iters: 565.0, loss: 0.6970321536064148\n",
      "Epoch: 113, Test Accuracy:67.85714285714286\n",
      "epoch: 114, iters: 570.0, loss: 0.5750945210456848\n",
      "Epoch: 114, Test Accuracy:71.42857142857143\n",
      "epoch: 115, iters: 575.0, loss: 0.7969985604286194\n",
      "Epoch: 115, Test Accuracy:71.42857142857143\n",
      "epoch: 116, iters: 580.0, loss: 0.5202322006225586\n",
      "Epoch: 116, Test Accuracy:67.85714285714286\n",
      "epoch: 117, iters: 585.0, loss: 0.3923662304878235\n",
      "Epoch: 117, Test Accuracy:67.85714285714286\n",
      "epoch: 118, iters: 590.0, loss: 0.3584315776824951\n",
      "Epoch: 118, Test Accuracy:69.64285714285714\n",
      "epoch: 119, iters: 595.0, loss: 0.5088253617286682\n",
      "Epoch: 119, Test Accuracy:67.85714285714286\n",
      "epoch: 120, iters: 600.0, loss: 0.26005691289901733\n",
      "Epoch: 120, Test Accuracy:73.21428571428571\n",
      "epoch: 121, iters: 605.0, loss: 0.3164374828338623\n",
      "Epoch: 121, Test Accuracy:76.78571428571429\n",
      "76.78571428571429\n",
      "epoch: 122, iters: 610.0, loss: 0.2623984217643738\n",
      "Epoch: 122, Test Accuracy:73.21428571428571\n",
      "epoch: 123, iters: 615.0, loss: 0.2710711658000946\n",
      "Epoch: 123, Test Accuracy:73.21428571428571\n",
      "epoch: 124, iters: 620.0, loss: 0.22767771780490875\n",
      "Epoch: 124, Test Accuracy:69.64285714285714\n",
      "epoch: 125, iters: 625.0, loss: 0.31103619933128357\n",
      "Epoch: 125, Test Accuracy:62.5\n",
      "epoch: 126, iters: 630.0, loss: 0.27602770924568176\n",
      "Epoch: 126, Test Accuracy:71.42857142857143\n",
      "epoch: 127, iters: 635.0, loss: 0.15201207995414734\n",
      "Epoch: 127, Test Accuracy:66.07142857142857\n",
      "epoch: 128, iters: 640.0, loss: 0.38454073667526245\n",
      "Epoch: 128, Test Accuracy:69.64285714285714\n",
      "epoch: 129, iters: 645.0, loss: 0.2621549069881439\n",
      "Epoch: 129, Test Accuracy:71.42857142857143\n",
      "epoch: 130, iters: 650.0, loss: 0.17847499251365662\n",
      "Epoch: 130, Test Accuracy:71.42857142857143\n",
      "epoch: 131, iters: 655.0, loss: 0.15380188822746277\n",
      "Epoch: 131, Test Accuracy:75.0\n",
      "epoch: 132, iters: 660.0, loss: 0.12200789898633957\n",
      "Epoch: 132, Test Accuracy:83.92857142857143\n",
      "83.92857142857143\n",
      "epoch: 133, iters: 665.0, loss: 0.29643958806991577\n",
      "Epoch: 133, Test Accuracy:80.35714285714286\n",
      "epoch: 134, iters: 670.0, loss: 0.08011170476675034\n",
      "Epoch: 134, Test Accuracy:80.35714285714286\n",
      "epoch: 135, iters: 675.0, loss: 0.0989006757736206\n",
      "Epoch: 135, Test Accuracy:67.85714285714286\n",
      "epoch: 136, iters: 680.0, loss: 0.5222886204719543\n",
      "Epoch: 136, Test Accuracy:75.0\n",
      "epoch: 137, iters: 685.0, loss: 0.2596709430217743\n",
      "Epoch: 137, Test Accuracy:82.14285714285714\n",
      "epoch: 138, iters: 690.0, loss: 0.11335650086402893\n",
      "Epoch: 138, Test Accuracy:78.57142857142857\n",
      "epoch: 139, iters: 695.0, loss: 0.22760674357414246\n",
      "Epoch: 139, Test Accuracy:82.14285714285714\n",
      "epoch: 140, iters: 700.0, loss: 0.11076899617910385\n",
      "Epoch: 140, Test Accuracy:83.92857142857143\n",
      "epoch: 141, iters: 705.0, loss: 0.166514590382576\n",
      "Epoch: 141, Test Accuracy:78.57142857142857\n",
      "epoch: 142, iters: 710.0, loss: 0.2779357433319092\n",
      "Epoch: 142, Test Accuracy:78.57142857142857\n",
      "epoch: 143, iters: 715.0, loss: 0.28407716751098633\n",
      "Epoch: 143, Test Accuracy:78.57142857142857\n",
      "epoch: 144, iters: 720.0, loss: 0.17061956226825714\n",
      "Epoch: 144, Test Accuracy:75.0\n",
      "epoch: 145, iters: 725.0, loss: 0.1574343889951706\n",
      "Epoch: 145, Test Accuracy:80.35714285714286\n",
      "epoch: 146, iters: 730.0, loss: 0.08300446718931198\n",
      "Epoch: 146, Test Accuracy:78.57142857142857\n",
      "epoch: 147, iters: 735.0, loss: 0.06408749520778656\n",
      "Epoch: 147, Test Accuracy:80.35714285714286\n",
      "epoch: 148, iters: 740.0, loss: 0.0767994225025177\n",
      "Epoch: 148, Test Accuracy:82.14285714285714\n",
      "epoch: 149, iters: 745.0, loss: 0.08485254645347595\n",
      "Epoch: 149, Test Accuracy:82.14285714285714\n",
      "epoch: 150, iters: 750.0, loss: 0.19035598635673523\n",
      "Epoch: 150, Test Accuracy:87.5\n",
      "87.5\n",
      "epoch: 151, iters: 755.0, loss: 0.0855853259563446\n",
      "Epoch: 151, Test Accuracy:78.57142857142857\n",
      "epoch: 152, iters: 760.0, loss: 0.13435208797454834\n",
      "Epoch: 152, Test Accuracy:82.14285714285714\n",
      "epoch: 153, iters: 765.0, loss: 0.07903855293989182\n",
      "Epoch: 153, Test Accuracy:75.0\n",
      "epoch: 154, iters: 770.0, loss: 0.049909114837646484\n",
      "Epoch: 154, Test Accuracy:75.0\n",
      "epoch: 155, iters: 775.0, loss: 0.302809476852417\n",
      "Epoch: 155, Test Accuracy:80.35714285714286\n",
      "epoch: 156, iters: 780.0, loss: 0.04975772649049759\n",
      "Epoch: 156, Test Accuracy:87.5\n",
      "epoch: 157, iters: 785.0, loss: 0.10152621567249298\n",
      "Epoch: 157, Test Accuracy:85.71428571428571\n",
      "epoch: 158, iters: 790.0, loss: 0.0697488859295845\n",
      "Epoch: 158, Test Accuracy:87.5\n",
      "epoch: 159, iters: 795.0, loss: 0.02517758309841156\n",
      "Epoch: 159, Test Accuracy:78.57142857142857\n",
      "epoch: 160, iters: 800.0, loss: 0.04090964049100876\n",
      "Epoch: 160, Test Accuracy:80.35714285714286\n",
      "epoch: 161, iters: 805.0, loss: 0.03824963420629501\n",
      "Epoch: 161, Test Accuracy:87.5\n",
      "epoch: 162, iters: 810.0, loss: 0.11620233952999115\n",
      "Epoch: 162, Test Accuracy:87.5\n",
      "epoch: 163, iters: 815.0, loss: 0.10698884725570679\n",
      "Epoch: 163, Test Accuracy:85.71428571428571\n",
      "epoch: 164, iters: 820.0, loss: 0.02844509482383728\n",
      "Epoch: 164, Test Accuracy:85.71428571428571\n",
      "epoch: 165, iters: 825.0, loss: 0.019168034195899963\n",
      "Epoch: 165, Test Accuracy:83.92857142857143\n",
      "epoch: 166, iters: 830.0, loss: 0.06558874249458313\n",
      "Epoch: 166, Test Accuracy:87.5\n",
      "epoch: 167, iters: 835.0, loss: 0.09000463038682938\n",
      "Epoch: 167, Test Accuracy:91.07142857142857\n",
      "91.07142857142857\n",
      "epoch: 168, iters: 840.0, loss: 0.040358029305934906\n",
      "Epoch: 168, Test Accuracy:87.5\n",
      "epoch: 169, iters: 845.0, loss: 0.017078541219234467\n",
      "Epoch: 169, Test Accuracy:80.35714285714286\n",
      "epoch: 170, iters: 850.0, loss: 0.028230905532836914\n",
      "Epoch: 170, Test Accuracy:82.14285714285714\n",
      "epoch: 171, iters: 855.0, loss: 0.024948865175247192\n",
      "Epoch: 171, Test Accuracy:83.92857142857143\n",
      "epoch: 172, iters: 860.0, loss: 0.025341622531414032\n",
      "Epoch: 172, Test Accuracy:83.92857142857143\n",
      "epoch: 173, iters: 865.0, loss: 0.037794679403305054\n",
      "Epoch: 173, Test Accuracy:83.92857142857143\n",
      "epoch: 174, iters: 870.0, loss: 0.054061099886894226\n",
      "Epoch: 174, Test Accuracy:83.92857142857143\n",
      "epoch: 175, iters: 875.0, loss: 0.016571156680583954\n",
      "Epoch: 175, Test Accuracy:85.71428571428571\n",
      "epoch: 176, iters: 880.0, loss: 0.12148270010948181\n",
      "Epoch: 176, Test Accuracy:89.28571428571429\n",
      "epoch: 177, iters: 885.0, loss: 0.017826378345489502\n",
      "Epoch: 177, Test Accuracy:87.5\n",
      "epoch: 178, iters: 890.0, loss: 0.009247630834579468\n",
      "Epoch: 178, Test Accuracy:91.07142857142857\n",
      "epoch: 179, iters: 895.0, loss: 0.13813304901123047\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 179, Test Accuracy:91.07142857142857\n",
      "epoch: 180, iters: 900.0, loss: 0.020338818430900574\n",
      "Epoch: 180, Test Accuracy:91.07142857142857\n",
      "epoch: 181, iters: 905.0, loss: 0.01514829695224762\n",
      "Epoch: 181, Test Accuracy:89.28571428571429\n",
      "epoch: 182, iters: 910.0, loss: 0.009589284658432007\n",
      "Epoch: 182, Test Accuracy:85.71428571428571\n",
      "epoch: 183, iters: 915.0, loss: 0.00956319272518158\n",
      "Epoch: 183, Test Accuracy:83.92857142857143\n",
      "epoch: 184, iters: 920.0, loss: 0.1524752974510193\n",
      "Epoch: 184, Test Accuracy:83.92857142857143\n",
      "epoch: 185, iters: 925.0, loss: 0.014115557074546814\n",
      "Epoch: 185, Test Accuracy:82.14285714285714\n",
      "epoch: 186, iters: 930.0, loss: 0.07756875455379486\n",
      "Epoch: 186, Test Accuracy:82.14285714285714\n",
      "epoch: 187, iters: 935.0, loss: 0.06741046160459518\n",
      "Epoch: 187, Test Accuracy:69.64285714285714\n",
      "epoch: 188, iters: 940.0, loss: 1.0113507509231567\n",
      "Epoch: 188, Test Accuracy:66.07142857142857\n",
      "epoch: 189, iters: 945.0, loss: 0.933855414390564\n",
      "Epoch: 189, Test Accuracy:64.28571428571429\n",
      "epoch: 190, iters: 950.0, loss: 0.8244433403015137\n",
      "Epoch: 190, Test Accuracy:64.28571428571429\n",
      "epoch: 191, iters: 955.0, loss: 0.36682432889938354\n",
      "Epoch: 191, Test Accuracy:73.21428571428571\n",
      "epoch: 192, iters: 960.0, loss: 0.437809020280838\n",
      "Epoch: 192, Test Accuracy:73.21428571428571\n",
      "epoch: 193, iters: 965.0, loss: 0.2723018229007721\n",
      "Epoch: 193, Test Accuracy:76.78571428571429\n",
      "epoch: 194, iters: 970.0, loss: 0.22482791543006897\n",
      "Epoch: 194, Test Accuracy:67.85714285714286\n",
      "epoch: 195, iters: 975.0, loss: 0.2929408550262451\n",
      "Epoch: 195, Test Accuracy:64.28571428571429\n",
      "epoch: 196, iters: 980.0, loss: 0.10312318801879883\n",
      "Epoch: 196, Test Accuracy:76.78571428571429\n",
      "epoch: 197, iters: 985.0, loss: 0.1930905431509018\n",
      "Epoch: 197, Test Accuracy:78.57142857142857\n",
      "epoch: 198, iters: 990.0, loss: 0.16006484627723694\n",
      "Epoch: 198, Test Accuracy:80.35714285714286\n",
      "epoch: 199, iters: 995.0, loss: 0.23893822729587555\n",
      "Epoch: 199, Test Accuracy:69.64285714285714\n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 200\n",
    "\n",
    "is_best = False\n",
    "best_accuracy = 0\n",
    "\n",
    "for epoch in tqdm(range(int(num_epochs))):\n",
    "    emoji_net.train()\n",
    "    for batch_idx, (inputs, labels) in enumerate(train_loader):\n",
    "        \n",
    "        \n",
    "        # clear grads\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        inputs = to_index(inputs,word2index,max_length = 15)\n",
    "        inputs = Variable(inputs).to(device)\n",
    "        \n",
    "        labels = Variable(labels).to(device)\n",
    "        \n",
    "        # forward pass\n",
    "        outputs = emoji_net(inputs)\n",
    "        \n",
    "        # get loss\n",
    "        loss = criterion(outputs, labels)\n",
    "        # backward\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        if batch_idx % 5 == 0:\n",
    "            print('epoch: {}, iters: {}, loss: {}'.format(epoch, \n",
    "            batch_idx + epoch*np.ceil(len(train_dataset)/32), loss.item()))\n",
    "       \n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        emoji_net.eval()\n",
    "        for batch_idx, (inputs, labels) in enumerate(test_loader):\n",
    "\n",
    "            inputs = to_index(inputs,word2index, max_length = 15)\n",
    "            inputs = Variable(inputs).to(device)\n",
    "            labels = Variable(labels)\n",
    "\n",
    "            outputs = emoji_net(inputs)\n",
    "            _,preds = torch.max(outputs.data, dim=1)\n",
    "\n",
    "\n",
    "            total += labels.size(0)\n",
    "            correct += float((preds.cpu() == labels).sum())\n",
    "\n",
    "        accuracy = 100* correct/total\n",
    "        print( 'Epoch: {}, Test Accuracy:{}'.format(epoch, accuracy))\n",
    "        \n",
    "        if accuracy > best_accuracy:\n",
    "            is_best = True\n",
    "            best_accuracy = accuracy\n",
    "            save_best(is_best, best_accuracy, emoji_net, epoch, 'models/')\n",
    "        else:\n",
    "            is_best = False\n",
    "       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Test the result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Load the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "saved = torch.load('models/best_model.pth')\n",
    "\n",
    "best_model = Emoji_Net(layer_num, input_dim,hidden_dim, output_dim, emb_weights)\n",
    "\n",
    "best_model.to(device)\n",
    "best_model.load_state_dict(saved['model_state_dict'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Test the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy:91.07142857142857\n"
     ]
    }
   ],
   "source": [
    "total = 0\n",
    "correct = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    best_model.eval()\n",
    "    for batch_idx, (inputs, labels) in enumerate(test_loader):\n",
    "\n",
    "        inputs = to_index(inputs,word2index, max_length = 15)\n",
    "        inputs = Variable(inputs).to(device)\n",
    "        labels = Variable(labels)\n",
    "\n",
    "        outputs = best_model(inputs)\n",
    "        _,preds = torch.max(outputs.data, dim=1)\n",
    "\n",
    "\n",
    "        total += labels.size(0)\n",
    "        correct += float((preds.cpu() == labels).sum())\n",
    "\n",
    "    accuracy = 100* correct/total\n",
    "    print( 'Test Accuracy:{}'.format(accuracy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91.07142857142857\n"
     ]
    }
   ],
   "source": [
    "print(saved['best_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
